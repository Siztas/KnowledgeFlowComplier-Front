### AI对齐悖论：对齐越精准，被误导风险越高

AI对齐领域致力于将AI系统与人类的目标、偏好和伦理原则对齐，显著提升了AI模型的输出质量、安全性和可信度。然而，本文揭示了一个根本性挑战——“AI对齐悖论”：我们越让AI模型符合我们的价值观，就越容易被对手误导偏离这些价值观。文章通过三个具体例子来说明语言模型中的AI对齐悖论：模型调整、输入调整和输出调整。模型调整是指对手操纵神经网络的高维内部状态向量，使模型对无害的提示给出不符合对齐的回应；输入调整是指对手通过精心操纵输入提示或进行长时间对话，诱导模型呈现出不符合对齐的人格；输出调整是指对手先让模型正常工作，然后使用单独的语言模型（价值编辑器）来最小限度地编辑对齐模型的输出，将其重新对齐到另一套价值观。随着AI对现实世界影响的加深，让广泛的研究人员意识到这一悖论并寻找突破方法，以确保AI造福人类，变得至关重要。