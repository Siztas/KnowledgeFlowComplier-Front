###MUROAN：多模态融合机制的鲁棒性评估与解耦攻击分析

本文系统性研究了多模态学习模型在对抗攻击下的鲁棒性问题，聚焦于多模态输入的融合机制，这是当前深度多模态模型（Deep Multimodal Models, DMMs）性能提升的核心技术。作者提出了一个新的评估框架 MUROAN（MUltimodal RObustness ANalyzer），以统一视角解析多模态模型的架构，揭示其对融合机制的依赖性及其潜在脆弱性。通过在图像与文本等模态间施加最小程度的数据干扰（称为“解耦攻击”），MUROAN 能够显著破坏模型的判别能力。在实验中，最小仅需修改输入空间的 1.16%，即可达到 100% 的攻击成功率。MUROAN 通过将 DMM 拆解为融合嵌入生成函数与基于该嵌入的分类函数，即形式上表示为 \$Z(x) = z\$ 和 \$y = M(z)\$，从而精准定位易受攻击的融合部分。作者进一步实证分析了当前多种主流的 DMM，如 ViLBERT、VisualBERT、MMBT 和 Pythia，并发现这些模型无一例外都容易被解耦攻击成功。相比之下，传统的单模态攻击（如 PGD 攻击）虽有破坏力，但其修改空间远大于解耦攻击，不具备识别融合关键点的能力。论文强调现有对抗训练方法不足以增强模型在融合机制上的鲁棒性，指出当前对多模态学习模型的安全性理解仍然有限，呼吁社区关注融合机制的脆弱性，推动更鲁棒的多模态模型设计。研究成果及代码已开源，以促进该方向后续的深入探索。
