### 探索企业中的提示工程实践

随着大型语言模型（LLMs）在企业中的广泛应用，提示工程逐渐成为开发高效 AI 应用的关键环节。提示工程是指通过自然语言指令来引导 LLMs 产生特定行为或输出的过程。尽管理论上任何人都可以通过自然语言与 LLMs 交互，但在实际应用中，尤其是对于复杂任务，设计有效的提示并非易事。这不仅需要技能和知识，还需要大量的迭代来确定模型行为并引导其完成特定目标。本文通过分析企业环境中用户对提示的编辑行为，揭示了提示工程的实践模式，并探讨了如何通过工具支持来提高提示工程的效率。

研究背景部分指出，随着指令调整和对齐技术的出现，提示成为与 LLMs 交互的主要方式。在企业中，开发者和 AI 实践者尝试开发提示以自动化各种复杂程度的知识任务，以提高组织效率并挖掘 AI 的价值。这些任务包括文档或转录的总结、代码或其他结构化输出的生成，以及基于内容的问答等。无论任务如何，提示通常包含各种组件，有时嵌入示例，并且需要符合特定要求和高准确度的输出。此外，企业环境可能需要使用更具挑战性的模型，原因包括成本和专业化。目前尚不清楚 LLM 是否能够执行给定任务，开发和优化提示需要大量努力来找出答案。尽管已有研究开始探索提示工程行为和提示结构，但提示工程仍是一个新兴领域，不同情境和领域的行为可能有所不同，目前对企业中从业者随时间编辑提示的情况了解甚少。

为了深入了解提示工程实践，研究者从一个企业级 LLM 提示环境中收集了大量交互数据。这些数据记录了用户对一组托管 LLM 的提示应用情况，使研究者能够研究随时间发生的编辑和优化过程。通过对 57 名用户的提示会话样本进行定性分析，研究者记录了用户编辑的提示部分、应用的编辑类型，以及是否撤销或重做编辑。

研究结果表明，提示编辑会话主要由提示编辑和模型切换组成。最常编辑的提示部分是上下文，其次是任务指令和标签，最常见的编辑类型是修改，即保持原意不变。此外，研究还发现，用户在编辑提示时，往往会同时进行多项编辑，这可能会影响对特定编辑效果的跟踪。大约 11% 的提示编辑撤销或重做了之前的编辑，这可能表明用户在记忆先前尝试的结果或确定哪些编辑可能改善输出方面存在挑战。研究还观察到，大多数分析的提示/用例都是基于上下文的，即输入、基础数据或示例嵌入在提示中，与任务指令分开。上下文是最常编辑的组件，反映了其在企业任务中的重要性。常见的上下文添加模式包括模拟对话和添加示例。用户还会替换和修改现有上下文，以开发和优化任务指令，然后通过切换不同的上下文来评估指令的鲁棒性。

研究的贡献在于提供了企业环境中不同用例的提示编辑实践的大规模分析以及相应的设计启示。研究结果揭示了用户在提示工程中的实际模式及其普遍性，为理解用户如何与 LLMs 交互以及如何改进提示工程工具提供了重要见解。尽管研究数据匿名，限制了对用户先前提示经验或其在组织中角色的了解，但研究样本涵盖了广泛的用户技能和背景，有助于缓解这一限制。未来的研究可以进一步探索如何通过更结构化的提示、提示历史记录与比较、变体创作、半自动探索变体以及基于用例特定指标的内置提示质量评估等方式来支持提示工程，以提高企业中 LLM 应用的效率和效果。