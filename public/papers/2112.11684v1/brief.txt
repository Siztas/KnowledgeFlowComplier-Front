###训练速度提升 50 倍？HP-GNN 如何做到图神经网络极致加速


HP-GNN 是一种用于在 CPU-FPGA 异构平台上实现高吞吐量图神经网络（GNN）训练的新框架。随着 GNN 在推荐系统、分子属性预测和交通预测等领域的广泛应用，如何高效地部署 GNN 训练成为研究热点。CPU-FPGA 平台因其可定制的数据路径和丰富的片上内存资源，为加速 GNN 训练提供了潜力，但其开发需要硬件设计专业知识，开发难度较大。HP-GNN 通过自动化的硬件映射流程解决了这一问题，它接受 GNN 模型和训练算法作为输入，并自动生成针对目标 CPU-FPGA 平台优化的实现。该框架包含四个核心组件：减少内存访问流量和随机访问的数据布局与内部表示；支持多种 GNN 模型的优化硬件模板；用于自动硬件映射的设计空间探索引擎；以及允许用户用少量代码指定 GNN 训练的高级 API。实验结果显示，HP-GNN 在两个主流采样训练算法（neighbor sampling 和 subgraph sampling）和两个 GNN 模型（GraphSAGE 和 GCN）上的实现，相比纯 CPU 和 CPU-GPU 平台分别平均提速55.67×55.67\times 和2.17×2.17\times，并且相较现有最先进的 GNN 训练实现最高可达4.45×4.45\times 的加速。论文还给出了 GNN 层的计算抽象模型，其中定义了包括图结构𝒢(𝒱,ℰ,𝑿)、各层节点集合𝒱^l、邻接矩阵𝑨^l、权重矩阵𝑾^l、特征矩阵𝑿^l、聚合函数Aggregate()和更新函数Update()等关键要素，并以 GCN 模型为例说明了其计算过程。