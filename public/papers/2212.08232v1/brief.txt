###基于不确定性引导的专家采样方法：提升离线强化学习样本效率

该论文提出了一种基于不确定性引导的专家采样方法（UGES），用于提升离线强化学习在机器人控制任务中的样本效率。针对现有离线强化学习算法在从次优行为策略数据中学习时样本复杂度较高的问题，研究者通过Q函数集成估计模型不确定性$\sigma^2=\frac{1}{M}\sum_{i=1}^{M}(Q_{\theta^i}(s,a)-\mu(s,a))^2$，当不确定性超过阈值$\epsilon$时策略性地注入人类专家示范数据。该方法建立在单策略集中性假设$C^*=\sup_{s,a}\frac{d^{\pi^*}(s,a)}{d^\mu(s,a)}$的理论基础上，通过降低集中性系数来提升学习效率。实验在MuJoCo的Cheetah、Ant环境和OffWorld Gym的Monolith视觉导航任务中验证，结果表明相比随机混合专家与次优数据的基线方法，UGES在Cheetah环境中实现2倍加速收敛，在Monolith任务中减少80%人类示范数据需求（从12,500降至2,500条成功轨迹）。该方法可与保守Q学习（CQL）等现有离线强化学习算法直接结合，在保持算法稳定性的同时显著降低对昂贵人类示范数据的依赖，为现实机器人应用提供了更可行的训练方案。