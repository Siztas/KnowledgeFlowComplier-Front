###个性化联邦学习：到底哪种方法最有效？实证研究告诉你


本文《An Empirical Study of Personalized Federated Learning》对个性化联邦学习（Personalized Federated Learning, PFL）方法进行了系统的实证研究。联邦学习作为一种分布式机器学习方法，其基本思想是在保护用户隐私和降低通信开销的前提下，由多个客户端和一个服务器共同训练模型。然而，联邦学习中面临的主要挑战是数据异质性（data heterogeneity），即各客户端本地数据的分布不同，这会导致标准联邦学习方法（如FedAvg）在非IID数据条件下性能大幅下降。为解决这一问题，近年来涌现出大量个性化联邦学习方法，旨在为每个客户端构建更贴合其本地数据分布的个性化模型。然而，以往的研究大多只在各自设定的实验条件下评估自己的方法，缺乏统一的比较标准。

本文的主要贡献是建立了一个统一的实验平台FedBench，对现有主流个性化联邦学习方法在多个数据集（如FEMNIST、Shakespeare、Sent140、MNIST、CIFAR-10）、多种客户端数量、数据样本规模以及异质性程度等设置下进行了系统评估。实验结果表明：（1）当前并不存在“冠军”方法，不同个性化方法在不同数据集和条件下表现差异显著；（2）在高度异质的数据场景中，个性化方法的性能通常优于标准方法，但当结合微调（fine-tuning）技术时，传统方法如FedAvg也能取得极具竞争力的效果；（3）随着数据异质性的增大，个性化方法的性能反而有提升趋势，表明异质性提供了更多个性化优化的空间。

在方法评估上，本文涵盖了三类模型：非个性化联邦学习（如FedAvg、FedProx）、个性化联邦学习（如HypCluster、FML、FedMe、LG-FedAvg、FedPer、FedRep、Ditto、pFedMe）以及非联邦学习方法（如Local Data Only和Centralized）。此外，为确保公平对比，作者为部分方法增加了后期微调步骤。论文在算法设计上，详细说明了标准联邦学习目标函数为：

$$
\min_{w_g} \sum_{i \in S} \frac{n_i}{N} \mathcal{T}_i(w_g), \quad \text{其中 } \mathcal{T}_i(w_g) = \frac{1}{n_i} \sum_{j=1}^{n_i} f_i(x_j, y_j; w_g)
$$

而个性化联邦学习目标函数为：

$$
\min_{w_{p_1}, ..., w_{p_{|S|}}} \sum_{i \in S} \mathcal{T}_i(w_{p_i})
$$

其中 $w_g$ 是全局模型参数，$w_{p_i}$ 是客户端 $i$ 的个性化模型参数，$f_i$ 是客户端的损失函数，$\mathcal{T}_i$ 是其期望损失。实验在PyTorch平台上实现，并在Tesla V100 GPU上运行。作者综合分析了影响模型性能的三大维度：客户端数量、总样本数及数据异质性度量（由Dirichlet分布参数 $\alpha_{label}$ 控制）。每个实验都进行了五次独立重复，并报告准确率的均值和标准差。

综上所述，本文通过大规模统一实验展示了个性化联邦学习方法在不同条件下的表现，指出了当前方法的局限性及微调策略的重要性，为后续研究提供了坚实的基准平台和深刻的经验洞察。FedBench工具的开源也为学术界和工业界提供了便利的实验基础，有助于推动该领域的持续发展。
