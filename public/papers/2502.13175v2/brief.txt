### 走向稳健与安全的具身智能：漏洞与攻击综述

具身智能系统，如机器人和自动驾驶汽车，正越来越多地融入现实世界应用，却面临着来自环境和系统层面因素的诸多漏洞。这些漏洞通过传感器欺骗、对抗性攻击以及任务和运动规划的失败等形式表现出来，给系统的稳健性和安全性带来了巨大挑战。尽管相关研究日益增多，但现有综述很少专门聚焦于具身智能系统的独特安全与安全挑战，大多要么关注通用人工智能漏洞，要么只着眼于孤立的方面，缺乏一个专门针对具身智能的统一框架。本综述填补了这一关键空白，对具身智能的漏洞进行了分类，分析了独特的对抗性攻击范式，探讨了针对大型视觉语言模型（LVLM）和大型语言模型（LLM）的攻击向量，评估了具身感知、决策和任务规划算法的稳健性挑战，并提出了增强具身智能系统安全性和可靠性的针对性策略，为理解具身智能中漏洞与安全之间的相互作用提供了全面框架。
具身智能作为人工智能的关键技术，在自动驾驶、工业自动化和智能家居系统等领域发挥着重要作用。这些系统通过整合感知、决策和执行，能够出色地处理复杂的现实任务。然而，它们对传感器、执行器和算法之间复杂交互的依赖，也使它们暴露于广泛的漏洞之中，包括动态复杂环境、对传感器的干扰和欺骗攻击以及系统故障等风险，引发了对未经授权行为和声誉损害的担忧，凸显了确保其安全可靠部署的稳健安全措施的迫切需求。
文章识别出具身系统的三个关键特征：自主性、具身性和认知性。自主性指系统做出明智独立决策的能力，使其能够适应动态不可预测的情境，但这种独立性也引入了漏洞，如在复杂环境中可能出现决策错误。具身性表示与物理环境互动的能力，将物理存在与决策过程相结合以实现无缝互动。认知性涵盖系统理解、推理和解释自身行为的能力，确保其行为与内部目标和外部约束相一致，但认知过程也可能通过传感器到模型的攻击或对学习模型的操纵而被利用。